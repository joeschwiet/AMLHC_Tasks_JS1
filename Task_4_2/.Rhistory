skewness_age <- skewness(FHS_uebung$AGE, na.rm = TRUE)
print(paste("Skewness of AGE: ", skewness_age))
# Berechnung der Kurtosis für AGE
kurtosis_age <- kurtosis(FHS_uebung$AGE, na.rm = TRUE)
print(paste("Kurtosis of AGE: ", kurtosis_age))
# Berechnung der Schiefe für SBP
skewness_sbp <- skewness(FHS_uebung$SBP, na.rm = TRUE)
print(paste("Skewness of SBP: ", skewness_sbp))
# Berechnung der Kurtosis für SBP
kurtosis_sbp <- kurtosis(FHS_uebung$SBP, na.rm = TRUE)
print(paste("Kurtosis of SBP: ", kurtosis_sbp))
library(haven)
FHS_uebung <- read.csv("FHS_uebung.csv")
str(FHS_uebung)
# Chi-Quadrat-Test
chisq.test(table(FHS_uebung$SBP_bin, FHS_uebung$CHD_inc))
# Chi-Quadrat-Test
chisq.test(table(FHS_uebung$SBP_bin, FHS_uebung$CHD_inc), correct = FALSE)
is.integer(FHS_uebung$SBP)
is.integer(FHS_uebung$AGE)
plot(FHS_uebung$AGE, FHS_uebung$SBP, main="Zusammenhang zwischen Alter und Blutdruck",
xlab="Alter", ylab="Blutdruck", pch=19, col="blue")
linear_modell <- lm(SBP ~ AGE, data=FHS_uebung)
summary(linear_modell)
multi_modell <- lm(SBP ~ AGE + SEX + CHOL, data = FHS_uebung)
summary(multi_modell)
FHS_uebung_clean <- na.omit(FHS_uebung)
full_model <- lm(SBP ~ SEX + AGE + CHOL + FRW + CIG, data = FHS_uebung_clean)
reduced_model <- step(full_model, direction = "backward")
summary(reduced_model)
class(FHS_uebung$CHD_inc)
unique(FHS_uebung$CHD_inc)
logistic_model <- glm(CHD_inc ~ SBP, data = FHS_uebung, family = binomial)
summary(logistic_model)
class(FHS_uebung$SBP)
class(FHS_uebung$SEX)
unique(FHS_uebung$SEX)
logistic_model <- glm(CHD_inc ~ SBP, data = FHS_uebung, family = binomial)
summary(logistic_model)
log_model_2 <- glm(CHD_inc ~ SBP + SEX, family = binomial, data = FHS_uebung)
summary(log_model_2)
# Erstellen des vollständigen Modells mit allen Prädiktoren
log_model_3 <- glm(CHD_inc ~ AGE + CHOL + SBP + CIG + FRW, data = FHS_uebung, family = binomial)
# Durchführung der Rückwärtselimination
log_model_3_reduced <- step(log_model_3, direction = "backward")
# Erstellen des vollständigen Modells mit allen Prädiktoren
log_model_3 <- glm(CHD_inc ~ AGE + CHOL + SBP + CIG + FRW, data = FHS_uebung_clean, family = binomial)
# Durchführung der Rückwärtselimination
log_model_3_reduced <- step(log_model_3, direction = "backward")
# Anzeigen des finalen Modells
summary(log_model_3_reduced)
```{r log regression 3}
# Erstellen des vollständigen Modells mit allen Prädiktoren
log_model_3 <- glm(CHD_inc ~ AGE + CHOL + SBP + CIG + FRW + SEX, data = FHS_uebung_clean, family = binomial)
# Durchführung der Rückwärtselimination
log_model_3_reduced <- step(log_model_3, direction = "backward")
# Anzeigen des finalen Modells
summary(log_model_3_reduced)
exp(0.915770−1.96×0.147290)
exp(0.915770 - 1.96×0.147290)
exp(0.915770 - 1.96 * 0.147290)
exp(0.915770 + 1.96 * 0.147290)
exp(0.915770 - 1.96 * 0.147290)
exp(0.018539 + 1.96 * 0.002416)
exp(0.018539 - 1.96 * 0.002416)
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
library(Hmisc)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_data)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
diabetes_data <- read.csv("diabetes.csv", header = TRUE, sep = ",")
install.packages("Hmisc")
install.packages("htmltools")
library(Hmisc)
install.packages("htmltools")
install.packages("Hmisc")
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Update the detect_outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
# Rank features using information gain (package FSelector)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
print(description)
install.packages("FSelector")
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
library(FSelector)
library(rJava)
library(FSelector)
str(diabetes_complete)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Print the information gain for each attribute
print(info_gain)
## Print the information gain for each attribute
print(info_gain)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
#install.packages("Hmisc")
#install.packages("htmltools")
#install.packages("FSelector")
#install.packages("rJava")
library(Hmisc)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Print the information gain for each attribute
print(info_gain)
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)[order(-info_gain$attr_importance), ]
print(ranked_features)
## Print the information gain values
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)
ranked_features <- ranked_features[order(-ranked_features$attr_importance), ]
## View the ranked features by information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
## Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
## Add row names as a new column in the data frame for readability
ranked_features$feature_name <- rownames(ranked_features)
## Print the ranked features with feature names and information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
## Print the ranked features with feature names and information gain
print(ranked_features)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Print the information gain for each attribute
print(info_gain)
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)[order(-info_gain$attr_importance), ]
print(ranked_features)
## Print the information gain values
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)
ranked_features <- ranked_features[order(-ranked_features$attr_importance), ]
## View the ranked features by information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)
ranked_features <- ranked_features[order(-ranked_features$attr_importance), ]
## View the ranked features by information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
## Print the information gain for each attribute
print(info_gain)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
# Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
# Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
# Add row names as a new column in the data frame for readability
ranked_features$feature_name <- rownames(ranked_features)
# Print the ranked features with feature names and information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
# Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
# Ensure that the row names, which are the feature names, are included as a column
info_gain_df$Feature <- rownames(info_gain_df)
# Remove the row names to avoid confusion
rownames(info_gain_df) <- NULL
# Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
# Print the sorted ranked features
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
# Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
# Ensure that the row names, which are the feature names, are included as a column
info_gain_df$Feature <- rownames(info_gain_df)
# Remove the row names to avoid confusion
rownames(info_gain_df) <- NULL
# Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
# Print the sorted ranked features
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
# Boxplot for the most discriminating feature
ggplot(diabetes_complete, aes(x = class, y = plas)) +
geom_boxplot() +
labs(title = "Boxplot of Plasma Glucose by Class",
x = "Class",
y = "Plasma Glucose Levels")
# Distribution plot for the most discriminating feature
ggplot(diabetes_complete, aes(x = plas, fill = class)) +
geom_histogram(binwidth = 10, position = "identity", alpha = 0.5) +
labs(title = "Distribution of Plasma Glucose by Class",
x = "Plasma Glucose Levels",
y = "Count") +
theme_minimal()
# Boxplot for the least discriminating feature
ggplot(diabetes_complete, aes(x = class, y = pedi)) +
geom_boxplot() +
labs(title = "Boxplot of Pedigree Function by Class",
x = "Class",
y = "Pedigree Function")
# Distribution plot for the least discriminating feature
ggplot(diabetes_complete, aes(x = pedi, fill = class)) +
geom_histogram(binwidth = 0.1, position = "identity", alpha = 0.5) +
labs(title = "Distribution of Pedigree Function by Class",
x = "Pedigree Function",
y = "Count") +
theme_minimal()
library(ggplot2)
# Extracting the scores for PC1 and PC2
scores_df <- data.frame(PC1 = pca_result$scores[,1], PC2 = pca_result$scores[,2])
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
# Load dataset food.csv
food_data <- read.csv("food.csv", header = TRUE, sep = ",")
# Analyze the dimensions of the dataset
dim_food_data <- dim(food_data) # Gets the dimensions of the data frame
cat("Dimensions of dataset: ", dim_food_data, "\n") # Prints out the dimensions
# Calculate the number of missing values in the dataset
num_missing_values <- sum(is.na(food_data)) # Counts the total number of NA values
cat("Number of missing values: ", num_missing_values, "\n") # Prints out the number of missing values
# Feature scaling using z-transformation (standardization)
scaled_food_data <- scale(food_data[,-1])
# To check the scaling, let's look at the summary of the first few features
# This gives the mean and standard deviation which should be 0 and 1, respectively, after scaling
summary_scaled_food_data <- summary(scaled_food_data)
print(summary_scaled_food_data) # Prints a summary statistics of the scaled data
# Perform PCA using the princomp function
pca_result <- princomp(scaled_food_data)
# Print a summary of the PCA results to get eigenvalues and the proportion of variance
summary(pca_result)
# View the loadings for the PCA components
loadings(pca_result)
# Eigenvalues can give us the variance explained by each principal component
pca_result$sdev^2
# To see the proportion of variance explained by the principal components
prop_var_explained <- pca_result$sdev^2 / sum(pca_result$sdev^2)
prop_var_explained
# Extracting the scores for PC1 and PC2
scores_df <- data.frame(PC1 = pca_result$scores[,1], PC2 = pca_result$scores[,2])
# Creating a score plot with PC1 and PC2
qplot(data = scores_df, x = PC1, y = PC2, xlab = "PC1", ylab = "PC2", main = "PCA Score Plot")
# Extracting the scores for PC1 and PC2
scores_df <- data.frame(PC1 = pca_result$scores[,1], PC2 = pca_result$scores[,2])
# Creating a score plot with PC1 and PC2
ggplot(data = scores_df, aes(x = PC1, y = PC2)) +
geom_point() +  # Adds a scatter plot layer
theme_minimal() +  # Optional: Applies a minimalistic theme
labs(title = "PCA Score Plot", x = "PC1 (Principal Component 1)", y = "PC2 (Principal Component 2)")  # Adds labels
```{r load dataset, echo = FALSE}
# Create the confusion matrix
install.packages(caret)
# Define the predicted and actual classes
predicted <- c("Benign", "Malignant", "Malignant")
actual <- c("Benign", "Benign", "Malignant")
# Create the confusion matrix
install.packages(caret)
library(caret)
# Create the confusion matrix
install.package(caret)
# Create the confusion matrix
install.packages(caret)
# Create the confusion matrix
install.packages("caret")
setwd(cd /Users/johannesschwietering/Library/Mobile\ Documents/com~apple~CloudDocs/Studium/UMIT/Modul\ 12/AMLHC_Tasks_JS1)
setwd("/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1")
setwd("/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1/Task_4_1")
> setwd("/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1/Task_4_2")
setwd("/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1/Task_4_2")
knitr::opts_chunk$set(echo = TRUE)
# Load the diabetes dataset
diabetes_data <- read.csv("diabetes.csv")
# View the first few rows of the dataset
head(diabetes_data)
library(caret)
# Create a partition with createDataPartition
set.seed(123)  # for reproducibility
trainIndex <- createDataPartition(diabetes_data$Outcome, p = 0.75, list = FALSE, times = 1)
trainIndex <- createDataPartition(diabetes_data$class, p = 0.75, list = FALSE, times = 1)
# Create the training dataset
trainSet <- diabetes_data[trainIndex, ]
# Create the test dataset
testSet <- diabetes_data[-trainIndex, ]
# Check the dimensions of the training and test sets
dim(trainSet)
dim(testSet)
library(randomForest)
# Define the tuning grid using expand.grid
tuningGrid <- expand.grid(mtry = 2:8)
# View the tuning grid
print(tuningGrid)
