print(ranked_features)
## Print the information gain values
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)
ranked_features <- ranked_features[order(-ranked_features$attr_importance), ]
## View the ranked features by information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
## Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
## Add row names as a new column in the data frame for readability
ranked_features$feature_name <- rownames(ranked_features)
## Print the ranked features with feature names and information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
## Print the ranked features with feature names and information gain
print(ranked_features)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Print the information gain for each attribute
print(info_gain)
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)[order(-info_gain$attr_importance), ]
print(ranked_features)
## Print the information gain values
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)
ranked_features <- ranked_features[order(-ranked_features$attr_importance), ]
## View the ranked features by information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
## Rank the features by information gain
ranked_features <- as.data.frame(info_gain)
ranked_features <- ranked_features[order(-ranked_features$attr_importance), ]
## View the ranked features by information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
## Print the information gain for each attribute
print(info_gain)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
# Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
# Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
# Add row names as a new column in the data frame for readability
ranked_features$feature_name <- rownames(ranked_features)
# Print the ranked features with feature names and information gain
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
# Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
# Ensure that the row names, which are the feature names, are included as a column
info_gain_df$Feature <- rownames(info_gain_df)
# Remove the row names to avoid confusion
rownames(info_gain_df) <- NULL
# Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
# Print the sorted ranked features
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
# Replace zeros with NAs for all numeric columns
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], function(x) replace(x, x == 0, NA))
# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
x[x < lower_bound | x > upper_bound] <- NA
return(x)
}
# Apply the function to replace outliers with NA in each numeric column
diabetes_data[sapply(diabetes_data, is.numeric)] <- lapply(diabetes_data[sapply(diabetes_data, is.numeric)], replace_outliers_with_NA)
# Now, select only the complete cases
diabetes_complete <- diabetes_data[complete.cases(diabetes_data), ]
str(diabetes_complete)
# [Optional: Describe single features (R function describe of package Hmisc)]
description <- describe(diabetes_complete)
print(description)
# Rank features using information gain (package FSelector)
## Convert the class variable to a factor
diabetes_complete$class <- as.factor(diabetes_complete$class)
## Calculate information gain for each feature
info_gain <- information.gain(class ~ ., diabetes_complete)
# Convert the results into a readable data frame format
info_gain_df <- as.data.frame(info_gain)
# Ensure that the row names, which are the feature names, are included as a column
info_gain_df$Feature <- rownames(info_gain_df)
# Remove the row names to avoid confusion
rownames(info_gain_df) <- NULL
# Sort the features by their information gain values in descending order
ranked_features <- info_gain_df[order(-info_gain_df$attr_importance), ]
# Print the sorted ranked features
print(ranked_features)
# Create boxplot and distribution plots of one discriminating (i.e., highest IG score) and one non-discriminating feature (i.e., smallest IG score)
# Boxplot for the most discriminating feature
ggplot(diabetes_complete, aes(x = class, y = plas)) +
geom_boxplot() +
labs(title = "Boxplot of Plasma Glucose by Class",
x = "Class",
y = "Plasma Glucose Levels")
# Distribution plot for the most discriminating feature
ggplot(diabetes_complete, aes(x = plas, fill = class)) +
geom_histogram(binwidth = 10, position = "identity", alpha = 0.5) +
labs(title = "Distribution of Plasma Glucose by Class",
x = "Plasma Glucose Levels",
y = "Count") +
theme_minimal()
# Boxplot for the least discriminating feature
ggplot(diabetes_complete, aes(x = class, y = pedi)) +
geom_boxplot() +
labs(title = "Boxplot of Pedigree Function by Class",
x = "Class",
y = "Pedigree Function")
# Distribution plot for the least discriminating feature
ggplot(diabetes_complete, aes(x = pedi, fill = class)) +
geom_histogram(binwidth = 0.1, position = "identity", alpha = 0.5) +
labs(title = "Distribution of Pedigree Function by Class",
x = "Pedigree Function",
y = "Count") +
theme_minimal()
library(ggplot2)
# Extracting the scores for PC1 and PC2
scores_df <- data.frame(PC1 = pca_result$scores[,1], PC2 = pca_result$scores[,2])
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
# Load dataset food.csv
food_data <- read.csv("food.csv", header = TRUE, sep = ",")
# Analyze the dimensions of the dataset
dim_food_data <- dim(food_data) # Gets the dimensions of the data frame
cat("Dimensions of dataset: ", dim_food_data, "\n") # Prints out the dimensions
# Calculate the number of missing values in the dataset
num_missing_values <- sum(is.na(food_data)) # Counts the total number of NA values
cat("Number of missing values: ", num_missing_values, "\n") # Prints out the number of missing values
# Feature scaling using z-transformation (standardization)
scaled_food_data <- scale(food_data[,-1])
# To check the scaling, let's look at the summary of the first few features
# This gives the mean and standard deviation which should be 0 and 1, respectively, after scaling
summary_scaled_food_data <- summary(scaled_food_data)
print(summary_scaled_food_data) # Prints a summary statistics of the scaled data
# Perform PCA using the princomp function
pca_result <- princomp(scaled_food_data)
# Print a summary of the PCA results to get eigenvalues and the proportion of variance
summary(pca_result)
# View the loadings for the PCA components
loadings(pca_result)
# Eigenvalues can give us the variance explained by each principal component
pca_result$sdev^2
# To see the proportion of variance explained by the principal components
prop_var_explained <- pca_result$sdev^2 / sum(pca_result$sdev^2)
prop_var_explained
# Extracting the scores for PC1 and PC2
scores_df <- data.frame(PC1 = pca_result$scores[,1], PC2 = pca_result$scores[,2])
# Creating a score plot with PC1 and PC2
qplot(data = scores_df, x = PC1, y = PC2, xlab = "PC1", ylab = "PC2", main = "PCA Score Plot")
# Extracting the scores for PC1 and PC2
scores_df <- data.frame(PC1 = pca_result$scores[,1], PC2 = pca_result$scores[,2])
# Creating a score plot with PC1 and PC2
ggplot(data = scores_df, aes(x = PC1, y = PC2)) +
geom_point() +  # Adds a scatter plot layer
theme_minimal() +  # Optional: Applies a minimalistic theme
labs(title = "PCA Score Plot", x = "PC1 (Principal Component 1)", y = "PC2 (Principal Component 2)")  # Adds labels
```{r load dataset, echo = FALSE}
setwd (/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1/Task_3_1)
setwd("/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1/Task_3_1")
# Load the necessary library for handling data
library(readr)
# Load the dataset named 'food.csv'
food_data <- read_csv("food.csv")
# Display the first few rows of the dataset to verify it loaded correctly
head(food_data)
# Preprocess the data using z-transformation
# The scale function centers and scales the data (mean = 0, SD = 1)
# Applying z-transformation to all numerical columns in the dataset
scaled_food_data <- scale(food_data)
library(dplyr)
install.packages("dplyr")
library(dplyr)
# Display the first few rows of the dataset to verify it loaded correctly
head(food_data)
# Load the dataset named 'food.csv'
food_data <- read_csv("food.csv", row.names=1)
# Load the dataset named 'food.csv'
food_data <- read.csv("food.csv", row.names=1)
# Display the first few rows of the dataset to verify it loaded correctly
head(food_data)
# Preprocess the data using z-transformation
# The scale function centers and scales the data (mean = 0, SD = 1)
# Applying z-transformation to all numerical columns in the dataset
scaled_food_data <- scale(food_data)
# Create a new data frame with the scaled data to handle further analyses if needed
scaled_food_data <- as.data.frame(scaled_food_data)
kmc <- kmeans(scaled_food_data,2)
head(kmc)
set.seed(123)
kmc <- kmeans(scaled_food_data,2)
head(kmc)
# Load the necessary libraries for handling data
install.packages("clusterCrit")
library(clusterCrit)
?cluster
?clusterCrit
cl <- intCriteria(scaled_food_data,kmc$cluster, "Silhouette")
cl <- intCriteria(scaled_food_data,kmc$cluster, "Silhouette")
scaled_food_data <- as.matrix(scaled_food_data)
cl <- intCriteria(scaled_food_data,kmc$cluster, "Silhouette")
print(cl)
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
kmc <- kmeans(scaled_food_data,3)
#lets have a look at the data
head(kmc)
scaled_food_data <- as.matrix(scaled_food_data)
cl <- intCriteria(scaled_food_data,kmc$cluster, "Silhouette")
print(cl)
# Iterate over k values from 2 to 5 to find the best k based on Silhouette score
for (k in k_values) {
# Apply KMeans clustering
kmc <- kmeans(scaled_food_data, centers = k, nstart = 25)
# Calculate the Silhouette coefficient
cl <- intCriteria(scaled_food_data, kmc$cluster, "Silhouette")
# Store the Silhouette score
silhouette_scores[k - 1] <- cl
# Print the cluster centers to inspect them - optional
print(paste("K =", k))
print(head(kmc$centers))
}
# Iterate over k values from 2 to 5 to find the best k based on Silhouette score
for (k in k_values) {
# Apply KMeans clustering
kmc <- kmeans(scaled_food_data, centers = k, nstart = 25)
# Calculate the Silhouette coefficient
cl <- intCriteria(scaled_food_data, kmc$cluster, "Silhouette")
# Store the Silhouette score
silhouette_scores[k - 1] <- cl
# Print the cluster centers to inspect them - optional
print(paste("K =", k))
print(head(kmc$centers))
}
set.seed(123)
kmc <- kmeans(scaled_food_data,2)
#lets have a look at the data
head(kmc)
scaled_food_data <- as.matrix(scaled_food_data)
cl <- intCriteria(scaled_food_data,kmc$cluster, "Silhouette")
print(cl)
# Load required libraries
library(clusterCrit)
# Set global options for knitr to display code
knitr::opts_chunk$set(echo = TRUE)
# Convert the scaled data to matrix format
scaled_food_data <- as.matrix(scaled_food_data)
# Initialize variables to store the results
silhouette_scores <- numeric(4)
k_values <- 2:5
# Set seed for reproducibility
set.seed(123)
# Iterate over k values from 2 to 5 to find the best k based on Silhouette score
for (k in k_values) {
# Apply KMeans clustering
kmc <- kmeans(scaled_food_data, centers = k, nstart = 25)
# Calculate the Silhouette coefficient
cl <- intCriteria(scaled_food_data, kmc$cluster, "Silhouette")
# Store the Silhouette score
silhouette_scores[k - 1] <- cl
# Print the cluster centers to inspect them - optional
print(paste("K =", k))
print(head(kmc$centers))
}
# Print all Silhouette scores for each k
names(silhouette_scores) <- paste("k =", k_values)
print(silhouette_scores)
# Determine the best k based on the maximum Silhouette score
optimal_k <- which.max(silhouette_scores) + 1  # Adjust index by 1
cat("The optimal number of clusters (k) based on the Silhouette coefficient is:", optimal_k, "\n")
print(silhouette_scores)
# Determine the best k based on the maximum Silhouette score
optimal_k <- which.max(silhouette_scores) + 1  # Adjust index by 1
cat("The optimal number of clusters (k) based on the Silhouette coefficient is:", optimal_k, "\n")
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data, scores = TRUE)
# Get PCA scores
scores <- pca_result$scores
# Add cluster assignments from KMeans to the PCA scores dataframe
scores_df <- data.frame(scores, Cluster = factor(kmc$cluster))
# Plot using qplot from ggplot2
qplot(PC1, PC2, data = scores_df, color = Cluster, main = "PCA Plot of KMeans Clustering")
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data, scores = TRUE)
# Get PCA scores
scores <- pca_result$scores
# Add cluster assignments from KMeans to the PCA scores dataframe
scores_df <- data.frame(scores, Cluster = factor(kmc$cluster))
# Plot using qplot from ggplot2
qplot(PC1, PC2, data = scores_df, color = Cluster, main = "PCA Plot of KMeans Clustering")
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data, scores = TRUE)
# Get PCA scores
scores <- pca_result$scores[,1:2]
# Add cluster assignments from KMeans to the PCA scores dataframe
scores_df <- data.frame(scores, Cluster = factor(kmc$cluster))
# Plot using qplot from ggplot2
qplot(PC1, PC2, data = scores_df, color = Cluster, main = "PCA Plot of KMeans Clustering")
knitr::opts_chunk$set(echo = TRUE)
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data, cor = TRUE, scores = TRUE)
# Get PCA scores
scores <- pca_result$scores[,1:2]
# Add cluster assignments from KMeans to the PCA scores dataframe
scores_df <- data.frame(scores, Cluster = factor(kmc$cluster))
# Plot using qplot from ggplot2
qlot(PC1, PC2, data = scores_df, color = Cluster, main = "PCA Plot of KMeans Clustering")
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data)
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"])
scores <- scores
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"], c)
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"])
scores <- scores*-1
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"])
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=kmc$cluster)
kmc <- kmeans(scaled_food_data, centers = 2)
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=kmc$cluster)
knitr::opts_chunk$set(echo = TRUE)
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data)
# Get PCA scores
scores <- pca_result$scores[,1:2]
scores <- scores*-1
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=kmc$cluster)
text(scores[,"Comp.1"], data_red[,"Comp.2"], labels=rownames(scaled_food_data), cex=0.5)
knitr::opts_chunk$set(echo = TRUE)
# Perform PCA on the scaled data
pca_result <- princomp(scaled_food_data)
# Get PCA scores
scores <- pca_result$scores[,1:2]
scores <- scores*-1
# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=kmc$cluster)
text(scores[,"Comp.1"], scores[,"Comp.2"], labels=rownames(scaled_food_data), cex=0.5)
hcf <- hclust(dist(scaled_food_data))
plot(hcf)
plot(hcf)
plot(hcf)
heatmap.2(scaled_food_data, scale="none")
heatmap(scaled_food_data, scale="none")
library(gplot)
install.packages(gplot)
install.packages(gplots)
install.packages("gplots")
library(gplots)
heatmap.2(scaled_food_data, scale="none")
heatmap.2(scaled_food_data, scale="none")
heatmap.2(scaled_food_data, scale="none")
heatmap.2(scaled_food_data, scale="none")
install.packages("fpc")
library(fpc)
dbc <- dbscan(scaled_food_data,eps=0.1)
dbc <- dbscan(scaled_food_data,eps=0.5)
dbc <- dbscan(scaled_food_data,eps=1, MinPts=3)
dbc <- dbscan(scaled_food_data,eps=2, MinPts=3)
print(dbc)
knitr::opts_chunk$set(echo = TRUE)
dbc <- dbscan(scaled_food_data,eps=2, MinPts=3)
print(dbc)
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=dbc$cluster)
text(scores[,"Comp.1"], scores[,"Comp.2"], labels=rownames(scaled_food_data), cex=0.5)
dbc <- dbscan(scaled_food_data,eps=2, MinPts=3)
print(dbc)
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=dbc$cluster)
text(scores[,"Comp.1"], scores[,"Comp.2"], labels=rownames(scaled_food_data), cex=0.5)
