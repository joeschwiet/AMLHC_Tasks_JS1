---
title: "Final Exam Modul 12"
author: "Johannes Schwietering"
date: "2024-06-22"
output: html_document

---

# How to predict readmission for diabetic patients?

## Introduction
The dataset titled "Diabetes 130-US Hospitals for Years 1999-2008" from Strack et al., published in 2014 in the journal BioMed Research International, serves as the foundation for my research.

**Primary Research Question**

- **Is the measurement of HbA1c associated with a reduction in readmission rates for individuals admitted to a hospital?**

**Secondary Research Questions**

- Which factors best predict patient readmission?
- What additional insights can be derived from the data? (This broad question allows for the application of various analytical methods.)

**Personal Interest**

The challenge of predicting hospital readmissions is of personal relevance to me, as a family member has diabetes. This research holds significant personal importance and drives my motivation to uncover meaningful insights.

Citation: "Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, ‚ÄúImpact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,‚Äù BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014."

## Method
To answer the research questions, the following steps will be conducted:

1. **Providing an Overview of the Dataset**
2. **Cleaning the Data**
3. **Preprocessing the Data**
4. **Feature Selection with Information Gain**
5. **Multinomial Logistic Regression (Without Covariates)**
6. **Logistic Regression with Covariates**
7. **Random Forest V1**
8. **Random Forest V2**
9. **Small Excursus to Unsupervised Learning**


```{r setup, echo=FALSE, results='hide', message=FALSE}
#Set Working Directory with setwd("path_to_folder")

#load libraries
library(ggplot2)
library(dplyr)
library(FSelector)
library(rpart)
library(rpart.plot)
library(nnet)
library(knitr)
library(caret)
library(clusterCrit)
library(gplots)
library(fpc)

```

## Getting an Overview

To get an overview, I will examine the structure and dimensions of the dataset, as well as the independent and dependent variables (readmission).


```{r Getting_Overview, echo=TRUE, message=FALSE, warning=FALSE}
#Load Data
diabetes_data <- read.csv("diabetic_data.csv")

# Getting an Overview 
# Structure of the dataset
str(diabetes_data)
dim(diabetes_data)
kable(head(diabetes_data), format = "html", table.attr = 'class="table table-striped table-hover"')

# Create a bar plot for the readmitted variable
bar_plot <- ggplot(diabetes_data, aes(x = readmitted)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Readmission Status of Patients",
       x = "Readmission Status",
       y = "Count") +
  theme_minimal() +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, color="black", size=4) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10)
  )

# Plot anzeigen
print(bar_plot)
```

### Learnings from the Overview

- Large dataset with over 100,000 encounters.
- Dependent variable is called "readmission."
- Main independent variable is called "A1Cresult."
- Overview of further independent variables.
- Majority of patients were not readmitted.


### Understanding the focus on encounter vs. patients

```{r encounte_patients, echo=TRUE, message=FALSE, warning=FALSE}
# how many encounters are there?
num_unique_encounters <- length(unique(diabetes_data$encounter_id))
print(paste("Number of unique encounters:", num_unique_encounters))

# Number of unique patients
num_unique_patients <- length(unique(diabetes_data$patient_nbr))
print(paste("Number of unique patients:", num_unique_patients))

# Count the number of occurrences of each patient_nbr
patient_counts <- table(diabetes_data$patient_nbr)

# Identify patient_nbr that are unique (appear only once)
unique_patient_nbr <- names(patient_counts[patient_counts == 1])

# Create a data frame excluding rows with unique patient_nbr
df_non_unique_patients <- diabetes_data[!(diabetes_data$patient_nbr %in% unique_patient_nbr), ]
readmission_status_non_unique <- table(df_non_unique_patients$readmitted)
cat("Readmission status for non-unique patients:\n")
print(readmission_status_non_unique)

# Create a data frame only containing rows with unique patient_nbr
df_unique_patients <- diabetes_data[diabetes_data$patient_nbr %in% unique_patient_nbr, ]

readmission_status_unique <- table(df_unique_patients$readmitted)
cat("Readmission status for unique patients:\n")
print(readmission_status_unique)

# Print the number of rows in each data frame to verify
cat("Number of rows in df_non_unique_patients:", nrow(df_non_unique_patients), "\n")
cat("Number of rows in df_unique_patients:", nrow(df_unique_patients), "\n")

```
![Understanding the "Encounters" and "Patient" Variable.](/Users/johannesschwietering/Library/Mobile Documents/com~apple~CloudDocs/Studium/UMIT/Modul 12/AMLHC_Tasks_JS1/AMLHC-final-exam/encounter.png)

### Additional Learnings

- The observations in the dataset are encounters and not individual patients.
- Patients can be included multiple times. While the majority is included only once, some patients are included up to 40 times.
- About 12,000 patients were readmitted but are only included in the dataset once. This raises concerns about the data quality.


## Cleaning and preprocessing the data

### Missing Values
As shown in the table below, most of the variables have no missing values. However, some variables contain a higher number of missing values, and the following decisions were made on how to deal with those:

- The variables `weight`, `payer_code`, `medical_specialty`, and `diag_3` are all excluded as they are not needed for the analysis.
- `race` is important, and therefore I decided to delete all rows with missing values for `race`.


```{r missing_values_code, echo=TRUE, message=FALSE, warning=FALSE}

# Replacing "?" with NA
diabetes_data[diabetes_data == "?"] <- NA

# Calculate the percentage of missing values for each attribute
missing_values <- 
  sapply(diabetes_data, function(x) sum(is.na(x)) / length(x) * 100)

# Create a data frame with the results
missing_values_df <- data.frame(
  attribute = names(missing_values),
  missing_percentage = missing_values
)

# Filter the data frame to include only variables with missing percentage > 0
missing_values_filtered <- missing_values_df[missing_values_df$missing_percentage > 0, ]

# Add a row for "All other Variables"
all_others_row <- data.frame(
  attribute = "All other Variables",
  missing_percentage = 0
)

# Combine the filtered data frame with the "All other Variables" row
final_missing_values_df <- rbind(missing_values_filtered, all_others_row)
final_missing_values_df$missing_percentage <- round(final_missing_values_df$missing_percentage, 2)
rownames(final_missing_values_df) <- NULL

# Print the resulting data frame
print(final_missing_values_df)

# Delete columns weight, payer:code, medical_specialty and diag_3
diabetes_data <- diabetes_data[, !(colnames(diabetes_data) %in% c("weight", "payer_code", "medical_specialty", "diag_3"))]

# Delete all rows where the variable "race" is NA
diabetes_data <- diabetes_data[!is.na(diabetes_data$race), ]
```

### Handling Outliers

The authors have already dealt with many outliers by transforming most numeric features into categorical features:

- The variable `A1Cresult` is divided into three groups: Values are ‚Äú>8‚Äù if the result was greater than 8%, ‚Äú>7‚Äù if the result was greater than 7% but less than 8%, ‚Äúnormal‚Äù if the result was less than 7%, and ‚Äúnone‚Äù if not measured.
- Age is grouped in 10-year intervals.

However, there are a number of variables for which the handling of outliers must be decided. I will visually check for outliers in the following variables by creating boxplots:

- `time_in_hospital`
- `num_lab_procedures`
- `num_medications`
- `number_diagnoses`

After inspecting the boxplots, the decision was made to replace outliers with NA.


```{r Outlier, echo=TRUE, message=FALSE, warning=FALSE}
# Box plot for time_in_hospital
boxplot(diabetes_data$time_in_hospital,
        main = "Box Plot of Time in Hospital",
        ylab = "Time in Hospital (days)",
        col = "lightblue")

# Box plot for num_lab_procedures
boxplot(diabetes_data$num_lab_procedures,
        main = "Box Plot of Number of Lab Procedures",
        ylab = "Number of Lab Procedures",
        col = "lightgreen")

# Box plot for num_medications
boxplot(diabetes_data$num_medications,
        main = "Box Plot of Number of Medications",
        ylab = "Number of Medications",
        col = "lightcoral")

# Box plot for number_diagnoses
boxplot(diabetes_data$number_diagnoses,
        main = "Box Plot of Number of Diagnoses",
        ylab = "Number of Diagnoses",
        col = "lightyellow")

# Define and apply a function for IQR based outlier detection and replace the detected outliers function to replace outliers with NA
replace_outliers_with_NA <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  x[x < lower_bound | x > upper_bound] <- NA
  return(x)
}

# List of columns to apply the function to
columns_to_check <- c("time_in_hospital", "num_lab_procedures", "num_medications", "number_diagnoses")

# Apply the function only to the specified columns
diabetes_data[columns_to_check] <- lapply(diabetes_data[columns_to_check], replace_outliers_with_NA)

# Check the summary to verify the changes
summary(diabetes_data[columns_to_check])

sapply(diabetes_data[columns_to_check], function(x) sum(is.na(x)))

# Now, select only the complete cases
diabetes_data <- diabetes_data[complete.cases(diabetes_data[columns_to_check]), ]

```

### Group Diagnosis

The main diagnosis (variable `diag_1`) is displayed as ICD-10 code. For conducting the logistic regression, it is recommended to group the diagnoses into different categories, as done by the authors of the research article. They recommend grouping the diagnostic codes into four groups:

- **Diabetes**: (ICD-9: 250.xx)
- **Diseases of the respiratory system**: (ICD-9: 460‚Äì519, 786)
- **Diseases of the circulatory system**: (ICD-9: 390‚Äì459, 785)
.

```{r Diagnosis, echo=TRUE, message=FALSE, warning=FALSE}
# Entfernen des Textes nach dem Punkt und Umwandeln in Integer
diabetes_data$diag_1_clean <- as.integer(sub("\\..*", "", diabetes_data$diag_1))

# Funktion zum Gruppieren der ICD-Werte
group_icd <- function(icd_code) {
  if (is.na(icd_code)) {
    return(NA)
  } else if (icd_code == 250) {
    return("Diabetes")
  } else if ((icd_code >= 460 && icd_code <= 519) || icd_code == 786) {
    return("respiratory")
  } else if ((icd_code >= 390 && icd_code <= 459) || icd_code == 785) {
    return("circulatory")
  } else {
    return("other")
  }
}

# Anwenden der Funktion auf die bereinigte Variable diag_1_clean
diabetes_data$diag_1_grouped <- sapply(diabetes_data$diag_1_clean, group_icd)

# √úberpr√ºfen der neuen Variable
table(diabetes_data$diag_1_grouped)

# Umwandeln der Krankheitsgruppen in einen Faktor
diabetes_data$diag_1_grouped <- as.factor(diabetes_data$diag_1_grouped)


```

### Convert Data Types and Feature Engineering

Most of the categorical variables were formatted as characters. We will change them to factors. This applies to:

- `race`
- `gender`
- `age`
- `max_glu_serum`
- `A1Cresult`
- `readmitted`
- `metformin`, `repaglinide`, `nateglinide`, `chlorpropamide`, `glimepiride`, `acetohexamide`, `glipizide`, `glyburide`, `tolbutamide`, `pioglitazone`, `rosiglitazone`, `acarbose`, `miglitol`, `troglitazone`, `tolazamide`, `examide`, `citoglipton`, `insulin`, `glyburide.metformin`, `glipizide.metformin`, `glimepiride.pioglitazone`, `metformin.rosiglitazone`, `metformin.pioglitazone`, `change`, `diabetesMed`


```{r Data_types, echo=TRUE, message=FALSE, warning=FALSE}
# List of variables to convert to factors
variables_to_convert <- c("race", "gender", "age", "max_glu_serum", "A1Cresult", "readmitted",
                          "metformin", "repaglinide", "nateglinide", "chlorpropamide", "glimepiride",
                          "acetohexamide", "glipizide", "glyburide", "tolbutamide", "pioglitazone",
                          "rosiglitazone", "acarbose", "miglitol", "troglitazone", "tolazamide", 
                          "examide", "citoglipton", "insulin", "glyburide.metformin", "glipizide.metformin",
                          "glimepiride.pioglitazone", "metformin.rosiglitazone", "metformin.pioglitazone",
                          "change", "diabetesMed", "admission_type_id","discharge_disposition_id", "admission_source_id" )

# Convert specified variables to factors
diabetes_data[variables_to_convert] <- lapply(diabetes_data[variables_to_convert], as.factor)

```

### Normalizing Data

I will normalize or standardize numerical features to bring them to a common scale when needed for the specific analysis.

## Feature Selection with Information Gain

Um einen ersten √úberblick √ºber den informativen Wert der Merkmale im Hinblick auf die Vorhersage der abh√§ngigen Variablen (Wiederaufnahme) zu erhalten, f√ºhren wir eine einfache Merkmalsauswahl mit Informationsgewinn durch. Der Informationsgewinn gibt dabei an, wie viel die Unsicherheit √ºber die abh√§ngige Variable verringert wird, wenn das jeweilige Merkmal bekannt ist.


```{r feature_selection, echo=TRUE, message=FALSE, warning=FALSE}
# Berechnung des Information Gain f√ºr die Merkmale
info_gain_results <- information.gain(readmitted ~ ., data = diabetes_data)
info_gain_results <- data.frame(attribute = rownames(info_gain_results), 
                                attribute_importance = info_gain_results$attr_importance)

ranked_info_gain_results <- info_gain_results[order(-info_gain_results$attribute_importance), ]

# Ergebnisse anzeigen
print(ranked_info_gain_results)
```

**Interpretation**

Die Berechnung des Information Gain f√ºr die Merkmale im Datensatz zur Vorhersage der Wiedereinweisung (readmitted) zeigt, dass "number_inpatient" (Anzahl der station√§ren Besuche des Patienten im Jahr vor dem Krankenhausaufenthalt) das Merkmal mit dem h√∂chsten Informationsgewinn ist, gefolgt von "diag_1" und "diag_2". Dies deutet darauf hin, dass die Anzahl der station√§ren Aufenthalte am st√§rksten zur Erkl√§rung der Varianz in der Zielvariable beitr√§gt. √úberraschenderweise ist ein weiteres wichtiges Merkmal die "patient_nbr" (Eindeutiger Identifikator eines Patienten), obwohl diese Variable keinen pr√§diktiven Wert hat, sondern nur eine zuf√§llige ID darstellt.

Merkmale wie "age", "race" und "A1Cresult" (HbA1c-Wert) zeigen im Vergleich dazu einen geringeren Informationsgewinn, was auf eine geringere Bedeutung f√ºr die Zielvariable hinweist. In den folgenden Untersuchungen werden wir uns die Auswirkungen des HbA1c-Werts noch genauer anschauen.

## Multinomiale Logistische Regression ohne Covariablen

Ich analysiere die Wahrscheinlichkeit der Wiederaufnahme von Patienten (readmitted) in eine Klinik basierend auf ihrem A1C-Ergebnis (A1Cresult). Die Referenzkategorie f√ºr die abh√§ngige Variable wurde auf "NO" gesetzt, was bedeutet, dass die Modellkoeffizienten die Wahrscheinlichkeit eines Patienten in den Kategorien "<30" und ">30" im Vergleich zur Kategorie "NO" beschreiben.


```{r multinomiale_regression, echo=TRUE, message=FALSE, warning=FALSE}
# √Ñndern der Referenzkategorie auf "NO"
diabetes_data$readmitted <- relevel(diabetes_data$readmitted, ref = "NO")

# Erstellen des Modells
multinom_model <- multinom(readmitted ~ A1Cresult, data = diabetes_data)

# Zusammenfassung des Modells anzeigen
summary(multinom_model)

# Extrahieren der Koeffizienten und Standardfehler
coeffs <- summary(multinom_model)$coefficients
std_errs <- summary(multinom_model)$standard.errors

# Berechnen der z-Werte
z_values <- coeffs / std_errs

# Berechnen der p-Werte
p_values <- 2 * (1 - pnorm(abs(z_values)))

# Ausgabe der p-Werte
p_values

```

**Interpretation**

Intercepts:

- F√ºr die Kategorie <30 betr√§gt der Intercept -1.7313592.
- F√ºr die Kategorie >30 betr√§gt der Intercept -0.4571126.

A1Cresult>8:

- Ein positiver Koeffizient von 0.04096509 f√ºr <30 deutet darauf hin, dass h√∂here A1C-Werte (>8) die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie <30 im Vergleich zur Referenzkategorie "NO" leicht erh√∂hen.

Der Koeffizient 0.04096509 bedeutet, dass der nat√ºrliche Logarithmus der Odds, dass ein Patient in die Kategorie <30 f√§llt, um 0.04096509 steigt, wenn der A1C-Wert >8 ist, 
Odds=exp(0.04096509)‚âà1.0418 Das bedeutet, dass die Odds, dass ein Patient in die Kategorie <30 f√§llt, um den Faktor 1.0418 steigen  Anders ausgedr√ºckt, es gibt eine etwa 4.18% h√∂here Chance, dass ein Patient in die Kategorie <30 f√§llt,

- Ein positiver Koeffizient von 0.06333964 f√ºr >30 deutet darauf hin, dass h√∂here A1C-Werte (>8) auch die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie >30 im Vergleich zur Referenzkategorie "NO" erh√∂hen.

A1CresultNone:

- Ein positiver Koeffizient von 0.2005823 f√ºr <30 bedeutet, dass das Fehlen eines A1C-Ergebnisses die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie <30 im Vergleich zu "NO" erh√∂ht.
- Ein positiver Koeffizient von 0.0568501 f√ºr >30 zeigt, dass das Fehlen eines A1C-Ergebnisses auch die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie >30 im Vergleich zu "NO" erh√∂ht.

A1CresultNorm:

- Ein negativer Koeffizient von -0.06985249 f√ºr <30 deutet darauf hin, dass normale A1C-Werte die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie <30 im Vergleich zu "NO" leicht verringern.
- Ein negativer Koeffizient von -0.12353739 f√ºr >30 deutet darauf hin, dass normale A1C-Werte die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie >30 im Vergleich zu "NO" ebenfalls verringern.

Standardfehler und Signifikanz
Die Standardfehler der Koeffizienten geben an, wie stark die gesch√§tzten Koeffizienten variieren. Kleinere Standardfehler deuten auf pr√§zisere Sch√§tzungen hin. Hier sind die Standardfehler relativ klein, was auf zuverl√§ssige Sch√§tzungen hindeutet.

Kategorie <30: Die Standardfehler f√ºr die Koeffizienten liegen zwischen 0.05859624 und 0.0779516.
Kategorie >30: Die Standardfehler f√ºr die Koeffizienten liegen zwischen 0.03649908 und 0.0487445.

Modellg√ºte

- Residual Deviance: 179575
- AIC: 179591


p-Werte

- Der p-Wert f√ºr die Kategorie <30 Tagen bei A1C Result:None ist 0.0007841546, was deutlich kleiner als 0.05 ist. Dies bedeutet, dass der Koeffizient f√ºr A1CresultNone hoch signifikant ist. Ein fehlendes A1C-Ergebnis hat also einen signifikanten Einfluss auf die Wahrscheinlichkeit der Wiederaufnahme in die Kategorie <30 im Vergleich zu "NO".

- **Das stimmt mit der Auswertung von Stark et al. √ºberein" With respect to readmission and taken as a whole without adjusting for covariates, measurement of HbA1c was associated with a significantly reduced rate of readmission (9.4 versus 8.7%, ùëÉ = 0.007).


## Bin√§re Logistische Regression mit Covariablen
```{r log_regression, echo=TRUE, message=FALSE, warning=FALSE}
# Zielvariable "readmitted" von drei auf zwei Auspr√§gungen reduzieren
# Kopie des Datensatzes erstellen
diabetes_data_reduced <- diabetes_data

# In Zeichenkette umwandeln
diabetes_data_reduced$readmitted <- as.character(diabetes_data_reduced$readmitted)

# Alle anderen Werte zu "YES" umkodieren
diabetes_data_reduced$readmitted[diabetes_data_reduced$readmitted != "NO"] <- "YES"

# Zur√ºck in einen Faktor umwandeln
diabetes_data_reduced$readmitted <- factor(diabetes_data_reduced$readmitted, levels = c("NO", "YES"))

# Einfache logistische Regression
 logistic_model <- glm(readmitted ~ A1Cresult + diag_1_grouped + number_inpatient + race + gender + age, data = diabetes_data_reduced, family = binomial)
 saveRDS(logistic_model, "logistic_model.rds")

# Zusammenfassung des Modells anzeigen
# logistic_model <- readRDS("logistic_model.rds")
summary(logistic_model)




```

**Interpretation**

Intercept: -1.551643

- Der Intercept ist signifikant (p < 0.001), was bedeutet, dass die Baseline-Odds (bei Referenzkategorie der Pr√§diktoren) f√ºr "YES" signifikant sind.
Pr√§diktoren:

A1Cresult:

- A1CresultNorm: Ein Koeffizient von -0.091169 (p = 0.049087) zeigt einen signifikanten negativen Einfluss. Patienten mit normalen A1C-Werten haben eine geringere Wahrscheinlichkeit, wieder aufgenommen zu werden.
- **Dieses Ergebnis weicht von der Publikation von Stark et al. ab!**

diag_1_grouped

- Diabetes: Ein Koeffizient von 0.137871 (p < 0.001) zeigt einen signifikanten positiven Einfluss. Patienten mit Diabetes als Hauptdiagnose haben eine h√∂here Wahrscheinlichkeit, wieder aufgenommen zu werden.
- other: Ein Koeffizient von -0.166225 (p < 0.001) zeigt einen signifikanten negativen Einfluss.


number_inpatient 

- Ein Koeffizient von 0.430899 (p < 0.001) zeigt einen sehr signifikanten positiven Einfluss. Jede zus√§tzliche station√§re Aufnahme erh√∂ht die Wahrscheinlichkeit der Wiederaufnahme signifikant.

race:

- Asian: Ein Koeffizient von -0.346613 (p < 0.001) zeigt einen signifikanten negativen Einfluss. Asiatische Patienten haben eine geringere Wahrscheinlichkeit, wieder aufgenommen zu werden.
- Caucasian: Ein Koeffizient von 0.065736 (p < 0.001) zeigt einen signifikanten positiven Einfluss.
- Hispanic: Ein Koeffizient von -0.124855 (p = 0.012297) zeigt einen signifikanten negativen Einfluss.
- Other: Ein Koeffizient von -0.169173 (p = 0.003484) zeigt einen signifikanten negativen Einfluss.

gender:

- Male: Ein Koeffizient von -0.077953 (p < 0.001) zeigt einen signifikanten negativen Einfluss. M√§nner haben eine geringere Wahrscheinlichkeit, wieder aufgenommen zu werden.

age:

- √Ñltere Patienten haben eine h√∂here Wahrscheinlichkeit, wieder aufgenommen zu werden, im Vergleich zur Referenzgruppe.

Modellg√ºte

- Null deviance: 128977 (bei 93358 Freiheitsgraden)
- Residual deviance: 123505 (bei 93336 Freiheitsgraden)
- AIC: 123551

Eine niedrigere Deviance und ein niedrigerer AIC-Wert deuten auf eine bessere Modellanpassung hin. Das Modell zeigt eine deutliche Verbesserung gegen√ºber dem Nullmodell.


## Random Forest V1

Die Analyse zielt darauf ab, ein pr√§diktives Modell zu entwickeln, um die Wahrscheinlichkeit der Wiederaufnahme von Patienten im Krankenhaus zu bestimmen. Dies wird erreicht, indem die wichtigsten Merkmale basierend auf dem Information Gain ausgew√§hlt und ein Random Forest Modell trainiert wird. Die Analyse hilft dabei, relevante Faktoren zu identifizieren, die die Wiederaufnahme beeinflussen, und liefert ein Modell, das zur Verbesserung des Patientenmanagements und zur Reduzierung der Wiederaufnahmeraten genutzt werden kann. Durch die Aufteilung der Daten in Trainings- und Testdatens√§tze wird die Modellg√ºte objektiv bewertet, um die Generalisierbarkeit der Vorhersagen sicherzustellen.

```{r random_forest_1, echo=TRUE, message=FALSE, warning=FALSE}
# W√§hlen Sie die wichtigsten Merkmale basierend auf dem Information Gain aus
top_features <- c(
  "number_inpatient", "diag_1_grouped", "A1Cresult","race", "gender", "age")

#top_features <- c( "number_inpatient", "diag_1", "diag_2", "race", "gender", "age", 
#  "admission_type_id", "discharge_disposition_id", "admission_source_id", 
#  "time_in_hospital", "num_lab_procedures", "num_procedures", "num_medications", 
#  "number_emergency", "number_diagnoses", "max_glu_serum", "A1Cresult", 
#  "change", "diabetesMed"
#)

# Erstellen eines Trainings- und Testdatensatzes

diabetes_data_reduced <- na.omit(diabetes_data_reduced)
# Setzen eines Zufallsgenerators f√ºr Reproduzierbarkeit
set.seed(42) 

# Aufteilen des Datensatzes in Trainings- und Testdaten
inTrain <- createDataPartition(diabetes_data_reduced$readmitted, p=0.75, list=FALSE)

training <- diabetes_data_reduced[inTrain, ]
testing <- diabetes_data_reduced[-inTrain, ]

# √úberpr√ºfen der Aufteilung
table(training$readmitted)
table(testing$readmitted)

# Erstellen der Matrix der unabh√§ngigen Variablen und des Zielvektors
X_train <- training[, top_features]
y_train <- training$readmitted
X_test <- testing[, top_features]
y_test <- testing$readmitted

# Definieren der Trainingskontrolle
trControl <- trainControl(method="cv", number=10)

# Trainieren des Random Forest Modells
#model_rf <- train(X_train, y_train, method="rf", preProcess=c("center","scale"), trControl=trControl, ntree=100)
#saveRDS(model_rf, "model_rf.rds")

model_rf <- readRDS("model_rf.rds")
y_pred_2 <- predict(model_rf, X_test)
confusionMatrix(y_pred_2, y_test)

```

**Interpretation**

Das trainierte Random Forest Modell wurde auf den Testdatensatz angewendet und erzielte eine Gesamtgenauigkeit (Accuracy) von 61.34%, mit einem Konfidenzintervall von 60.71% bis 61.96%. Die Sensitivit√§t, die die F√§higkeit des Modells misst, tats√§chliche positive F√§lle (Nicht-Wiederaufnahmen, "NO") korrekt zu identifizieren, betrug 77.17%, w√§hrend die Spezifit√§t, die die F√§higkeit misst, tats√§chliche negative F√§lle (Wiederaufnahmen, "YES") korrekt zu identifizieren, bei 43.16% lag. Diese Ergebnisse zeigen, dass das Modell gut darin ist, Patienten zu identifizieren, die nicht wiederaufgenommen werden, hat jedoch Schwierigkeiten bei der korrekten Identifizierung von Patienten, die wiederaufgenommen werden. Die relativ niedrigen Werte f√ºr die Positiven und Negativen Vorhersagewerte (60.92% bzw. 62.22%) sowie der Kappa-Wert von 0.2074 deuten darauf hin, dass das Modell verbessert werden k√∂nnte. Insgesamt zeigt das Modell ein gewisses Potenzial, performt jedoch viel zu schlecht um klinisch n√ºtzlich zu sein. 


## Random Forest V2

Hilft es, wenn wir die Variable "diag_1" nicht gruppiert verwenden sondern in der urspr√ºnglichen Version belassen? 

```{r random_forest_2, echo=TRUE, message=FALSE, warning=FALSE}
# W√§hlen Sie die wichtigsten Merkmale basierend auf dem Information Gain aus
top_features <- c(
  "number_inpatient", "diag_1", "A1Cresult")

#top_features <- c( "number_inpatient", "diag_1", "diag_2", "race", "gender", "age", 
#  "admission_type_id", "discharge_disposition_id", "admission_source_id", 
#  "time_in_hospital", "num_lab_procedures", "num_procedures", "num_medications", 
#  "number_emergency", "number_diagnoses", "max_glu_serum", "A1Cresult", 
#  "change", "diabetesMed"
#)

# Erstellen eines Trainings- und Testdatensatzes

diabetes_data_reduced <- na.omit(diabetes_data_reduced)
# Setzen eines Zufallsgenerators f√ºr Reproduzierbarkeit
set.seed(42) 

# Aufteilen des Datensatzes in Trainings- und Testdaten
inTrain <- createDataPartition(diabetes_data_reduced$readmitted, p=0.75, list=FALSE)

training <- diabetes_data_reduced[inTrain, ]
testing <- diabetes_data_reduced[-inTrain, ]

# √úberpr√ºfen der Aufteilung
table(training$readmitted)
table(testing$readmitted)

# Erstellen der Matrix der unabh√§ngigen Variablen und des Zielvektors
X_train <- training[, top_features]
y_train <- training$readmitted
X_test <- testing[, top_features]
y_test <- testing$readmitted

# Definieren der Trainingskontrolle
trControl <- trainControl(method="cv", number=10)

# Trainieren des Random Forest Modells
# model_rf_2 <- train(X_train, y_train, method="rf", preProcess=c("center","scale"), trControl=trControl, ntree=100)
#saveRDS(model_rf_2, "model_rf_2.rds")

 model_rf_2 <- readRDS("model_rf_2.rds")

y_pred <- predict(model_rf_2, X_test)
confusionMatrix(y_pred, y_test)

```

Das Ergebnis zeigt, dass die Vorhersagekraft kaum besser geworden ist. 

# Fazit

1. Der HbA1C Wert wird nur selten bestimmt <50%
2. Die Vorhersagekraft des HbA1C Werts auf readmission ist sehr gering: Wenn ein erh√∂hter HbA1C Wert gemessen wird f√ºhrt das zu einer etwa 4.18% h√∂here Chance der Wiederaufnahme in <30 Tagen. 
3. Die Anzahl an bisherigen Aufenthalte ist die Variable mit der st√§rksten Vorhersagekraft: jede zus√§tzliche station√§re Aufnahme (number_inpatient) erh√∂ht die Chance (Odds) der Wiederaufnahme um etwa 53.88%. 
4. Ein Random-Forest Modell zur Vorhersage der Wiederaufnahme mit den gegebenen Variablen hat eine geringe Accuracy (ca. 0.6)

## Unsupervised Learning

Dies ist nur eine Spielwiese um Methoden des unsupervised Learnings auszuprobieren. 

```{r Unsupervised, echo=TRUE, message=FALSE, warning=FALSE}

# Alle nicht-numerischen Variablen aus dem Datensatz ausschlie√üen
scaled_diabetes_data <- diabetes_data[, sapply(diabetes_data, is.numeric)]

# Ausschlie√üen der Variablen encounter_id und diag_1_clean aus scaled_diabetes_data
scaled_diabetes_data <- scaled_diabetes_data[, !(colnames(scaled_diabetes_data) %in% c("encounter_id", "diag_1_clean", "patient_nbr"))]

# Zuf√§llige Auswahl von 500 Zeilen aus dem Datensatz
set.seed(123) # F√ºr Reproduzierbarkeit
scaled_diabetes_data <- scaled_diabetes_data[sample(nrow(scaled_diabetes_data), 100), ]

# Applying z-transformation to all numerical columns in the dataset
scaled_diabetes_data <- scale(scaled_diabetes_data)

# Convert the scaled data to matrix format
scaled_diabetes_data <- as.matrix(scaled_diabetes_data)

# Initialize variables to store the results
silhouette_scores <- numeric(4)
k_values <- 2:5

# Set seed for reproducibility
set.seed(123)

# Iterate over k values from 2 to 5 to find the best k based on Silhouette score
for (k in k_values) {
  # Apply KMeans clustering
  kmc <- kmeans(scaled_diabetes_data, centers = k)
  
  # Calculate the Silhouette coefficient
  cl <- intCriteria(scaled_diabetes_data, kmc$cluster, "Silhouette")
  
  # Store the Silhouette score
  silhouette_scores[k - 1] <- cl
  
  # Print the cluster centers to inspect them
  print(paste("K =", k))
  print(head(kmc$centers))
}

# Print all Silhouette scores for each k
names(silhouette_scores) <- paste("k =", k_values)
print(silhouette_scores)

# Determine the best k based on the maximum Silhouette score
optimal_k <- which.max(silhouette_scores) + 1  # Adjust index by 1
cat("The optimal number of clusters (k) based on the Silhouette coefficient is:", optimal_k, "\n")

 kmc <- kmeans(scaled_diabetes_data, centers = 2)
 
 # Perform PCA on the scaled data
pca_result <- princomp(scaled_diabetes_data)

# Get PCA scores
scores <- pca_result$scores[,1:2]
scores <- scores*-1

# Plot using qplot from ggplot2
plot(scores[, "Comp.1"], scores[,"Comp.2"], col=kmc$cluster)
text(scores[,"Comp.1"], scores[,"Comp.2"], labels=rownames(scaled_diabetes_data), cex=0.5)

hcf <- hclust(dist(scaled_diabetes_data))
  plot(hcf)
  
heatmap.2(scaled_diabetes_data, scale="none")

 dbc <- dbscan(scaled_diabetes_data,eps=2, MinPts=3)
  print(dbc)
  
 plot(scores[, "Comp.1"], scores[,"Comp.2"], col=dbc$cluster)
  text(scores[,"Comp.1"], scores[,"Comp.2"], labels=rownames(scaled_diabetes_data), cex=0.5)
```
